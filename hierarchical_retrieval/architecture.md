# Hierarchical Retrieval System - Architecture Overview

## ðŸŽ¯ System Purpose

Ù†Ø¸Ø§Ù… Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ù‡Ø±Ù…ÙŠ Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØŒ ÙŠØ³ØªØ®Ø¯Ù… **3 Ø·Ø¨Ù‚Ø§Øª Ù…Ù†ÙØµÙ„Ø©** Ù…Ù† Ø§Ù„Ù€ embeddings Ù„ØªØ­Ø³ÙŠÙ† Ø¯Ù‚Ø© Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ.

---

## ðŸ—ï¸ Architecture Components

```mermaid
graph TB
    A[User Query] --> B[Query Embedding BGE-M3]
    B --> C[Layer 1: Title Search]
    B --> D[Layer 2: Filename Search]
    B --> E[Layer 3: Content Search]
    
    C --> F[Score Comparison & Thresholding]
    D --> F
    E --> F
    
    F --> G{Best Match?}
    
    G -->|Title Match| H[Get Chunk + 3-4 Context]
    G -->|Filename Match| I[Get All Video Chunks]
    G -->|Content Match| J[Get Chunk + 1-2 Context]
    
    H --> K[Ranked Results]
    I --> K
    J --> K
    
    style A fill:#e1f5ff
    style K fill:#c8e6c9
    style F fill:#fff9c4
```

---

## ðŸ“Š Three-Layer Embedding Strategy

### Layer 1: **Title Embeddings** (`embedding_type = "title"`)
- **Input**: `topicTitle` ÙÙ‚Ø·
- **Purpose**: Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹
- **Threshold**: 0.65
- **Use case**: Ø¹Ù†Ø¯Ù…Ø§ ÙŠØ³Ø£Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ù† Ù…ÙˆØ¶ÙˆØ¹ Ù…Ø­Ø¯Ø¯ Ø¨ÙˆØ¶ÙˆØ­

### Layer 2: **Filename Embeddings** (`embedding_type = "filename"`)
- **Input**: `filename` ÙÙ‚Ø·
- **Purpose**: ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ø£Ù†Ø³Ø¨ ÙƒÙˆØ­Ø¯Ø© ÙƒØ§Ù…Ù„Ø©
- **Threshold**: 0.60
- **Use case**: Ø¹Ù†Ø¯Ù…Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¹Ø§Ù… ÙˆÙŠØ®Øµ ÙÙŠØ¯ÙŠÙˆ ÙƒØ§Ù…Ù„

### Layer 3: **Content Embeddings** (`embedding_type = "content"`)
- **Input**: `topicContent` ÙÙ‚Ø·
- **Purpose**: Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ù…ÙŠÙ‚ ÙÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù†ØµÙŠ
- **Threshold**: 0.55
- **Use case**: fallback Ø£Ùˆ Ø¹Ù†Ø¯Ù…Ø§ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø£Ù‚Ø±Ø¨ Ù…Ù† Ø§Ù„Ø¹Ù†ÙˆØ§Ù†

---

## ðŸ” Retrieval Logic (Priority Order)

```
1. Calculate scores for all 3 layers
2. Compare with thresholds:
   
   IF title_score â‰¥ 0.65 AND title_score is MAX:
      â†’ retrieval_mode = "by_title"
      â†’ Return: main chunk + 3-4 context chunks from same video
   
   ELSE IF filename_score â‰¥ 0.60 AND filename_score is MAX:
      â†’ retrieval_mode = "by_filename"
      â†’ Return: ALL chunks from matched video (ranked by similarity)
   
   ELSE IF content_score â‰¥ 0.55 AND content_score is MAX:
      â†’ retrieval_mode = "by_content"
      â†’ Return: main chunk + 1-2 context chunks
   
   ELSE:
      â†’ retrieval_mode = "no_strong_match"
      â†’ Return: top-k from content layer with warning
```

---

## ðŸ’¾ Qdrant Schema

### Collection: `moshrif_knowledge_v3`

**Vector Config**:
- Size: 1024
- Distance: Cosine

**Point Structure**:
```python
{
    "id": int,  # unique point ID
    "vector": [float] * 1024,
    "payload": {
        "video_id": int,
        "filename": str,
        "telegram_url": str,
        "chunk_id": int | None,  # None for filename embeddings
        "chunk_title": str,
        "chunk_content": str,
        "embedding_type": "title" | "filename" | "content"
    }
}
```

---

## ðŸŽ² Example Scenarios

### Scenario 1: Title Match
**Query**: "Ø§Ø²Ø§ÙŠ Ø§Ø­ÙØ¸ Ø´ØºÙÙŠ ÙÙŠ Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©ØŸ"

1. Title score = 0.78 âœ… (> 0.65, highest)
2. **Action**: Get chunk with title "ÙƒÙŠÙÙŠØ© Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø´ØºÙ"
3. **Context**: + 3 nearby chunks from same video
4. **Mode**: `by_title`

### Scenario 2: Filename Match
**Query**: "Ø§Ø²Ø§ÙŠ Ù…ØµØ± ØªØ¨Ù‚Ù‰ Ø§Ù„Ù‡Ù†Ø¯ ÙÙŠ Ø§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ØŸ"

1. Filename score = 0.72 âœ… (> 0.60, highest)
2. **Action**: Get ALL chunks from matched video
3. **Ranking**: Sort by content similarity internally
4. **Mode**: `by_filename`

### Scenario 3: Content Match
**Query**: "ÙŠØ¹Ù†ÙŠ Ø§ÙŠÙ‡ cosine similarityØŸ"

1. Content score = 0.68 âœ… (> 0.55, highest)
2. **Action**: Get specific chunk explaining the term
3. **Context**: + 1-2 chunks for context
4. **Mode**: `by_content`

---

## âš¡ Performance Optimizations

1. **Batch Processing**: Insert embeddings in batches of 64
2. **Single Collection**: All 3 layers in one collection (filter by `embedding_type`)
3. **Metadata in Payload**: Avoid extra lookups
4. **Local Qdrant**: Embedded mode for speed

---

## ðŸ”§ Tech Stack

- **Embedding Model**: BGE-M3 (1024-dim, Arabic-optimized)
- **Vector DB**: Qdrant (local/embedded)
- **Framework**: Python 3.10+
- **Libraries**: 
  - `qdrant-client==1.16.1`
  - `requests` (for embedding API)
  - `typing` (type hints)
