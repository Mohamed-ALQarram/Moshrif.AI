"""
Arabic Text Normalization Script
==================================
Normalizes Arabic text in JSON file:
  - Remove diacritics (ØªØ´ÙƒÙŠÙ„)
  - Normalize Alef variants (Ø£ØŒ Ø¥ØŒ Ø¢ØŒ Ø¡ â†’ Ø§)
  - Remove underscores and hyphens
  - Clean extra whitespace
"""

import json
import re
from pathlib import Path

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Configuration
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

INPUT_FILE = Path("Moshrif-knowledge-chunks.json")
OUTPUT_FILE = Path("Moshrif-knowledge-chunks-normalized.json")
BACKUP_FILE = Path("Moshrif-knowledge-chunks-backup.json")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Arabic Normalization Functions
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def remove_diacritics(text: str) -> str:
    """
    Remove Arabic diacritics (ØªØ´ÙƒÙŠÙ„).
    
    Diacritics include:
    - Ù (Fatha)
    - Ù (Damma)
    - Ù (Kasra)
    - Ù‘ (Shadda)
    - Ù’ (Sukun)
    - Ù‹ (Tanween Fath)
    - ÙŒ (Tanween Damm)
    - Ù (Tanween Kasr)
    """
    # Arabic diacritics Unicode range
    arabic_diacritics = re.compile(r'[\u064B-\u0652\u0670]')
    return arabic_diacritics.sub('', text)


def normalize_alef(text: str) -> str:
    """
    Normalize all Alef variants to simple Alef (Ø§).
    
    Variants:
    - Ø£ (Alef with Hamza above)
    - Ø¥ (Alef with Hamza below)
    - Ø¢ (Alef with Madda)
    - Ø¡ (Hamza alone) - keep this for now, only normalize when on Alef
    """
    # Normalize Alef variants
    text = re.sub('[Ø¥Ø£Ø¢]', 'Ø§', text)
    return text


def normalize_yaa(text: str) -> str:
    """
    Normalize Yaa variants.
    """
    # Ù‰ (Alef Maksura) â†’ ÙŠ (Yaa)
    text = text.replace('Ù‰', 'ÙŠ')
    return text


def normalize_taa(text: str) -> str:
    """
    Normalize Taa Marbuta.
    """
    # Ø© (Taa Marbuta) â†’ Ù‡ (Haa) - optional, comment out if not needed
    # text = text.replace('Ø©', 'Ù‡')
    return text


def remove_special_chars(text: str) -> str:
    """
    Remove underscores, hyphens, and other special characters.
    """
    # Remove _ and -
    text = text.replace('_', ' ')
    text = text.replace('-', ' ')
    
    # Remove multiple spaces
    text = re.sub(r'\s+', ' ', text)
    
    return text.strip()


def normalize_arabic_text(text: str) -> str:
    """
    Apply all normalization steps.
    """
    if not text or not isinstance(text, str):
        return text
    
    # 1. Remove diacritics
    text = remove_diacritics(text)
    
    # 2. Normalize Alef
    text = normalize_alef(text)
    
    # 3. Normalize Yaa
    text = normalize_yaa(text)
    
    # 4. Normalize Taa (optional)
    text = normalize_taa(text)
    
    # 5. Remove special characters
    text = remove_special_chars(text)
    
    return text


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# JSON Processing
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def normalize_video(video: dict) -> dict:
    """
    Normalize all text fields in a video object.
    """
    # Normalize filename
    if 'filename' in video:
        video['filename'] = normalize_arabic_text(video['filename'])
    
    # Normalize telegram_url (keep as is, no normalization)
    # telegram_url stays the same
    
    # Normalize chunks
    if 'chunks' in video:
        for chunk in video['chunks']:
            if 'topicTitle' in chunk:
                chunk['topicTitle'] = normalize_arabic_text(chunk['topicTitle'])
            
            if 'topicContent' in chunk:
                chunk['topicContent'] = normalize_arabic_text(chunk['topicContent'])
    
    return video


def normalize_json_file():
    """
    Main normalization pipeline.
    """
    print("="*80)
    print("Arabic Text Normalization")
    print("="*80)
    
    # Check if file exists
    if not INPUT_FILE.exists():
        print(f"âŒ Error: File not found: {INPUT_FILE}")
        return
    
    # Create backup
    print(f"\nğŸ“¦ Creating backup: {BACKUP_FILE}")
    with INPUT_FILE.open('r', encoding='utf-8') as f:
        data = json.load(f)
    
    with BACKUP_FILE.open('w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… Backup created")
    
    # Process videos
    print(f"\nğŸ”„ Normalizing {len(data)} videos...")
    
    total_chunks = 0
    for i, video in enumerate(data, 1):
        video = normalize_video(video)
        total_chunks += len(video.get('chunks', []))
        
        if i % 50 == 0:
            print(f"   Processed {i}/{len(data)} videos...")
    
    print(f"âœ… Normalized {len(data)} videos, {total_chunks} chunks")
    
    # Save normalized data
    print(f"\nğŸ’¾ Saving to: {OUTPUT_FILE}")
    with OUTPUT_FILE.open('w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… Saved successfully")
    
    # Show examples
    print("\n" + "="*80)
    print("ğŸ“Š Normalization Examples:")
    print("="*80)
    
    if data and 'chunks' in data[0] and data[0]['chunks']:
        first_chunk = data[0]['chunks'][0]
        print(f"\nFilename: {data[0].get('filename', 'N/A')}")
        print(f"Title: {first_chunk.get('topicTitle', 'N/A')[:100]}...")
        print(f"Content: {first_chunk.get('topicContent', 'N/A')[:150]}...")
    
    print("\n" + "="*80)
    print("âœ… Normalization complete!")
    print("="*80)
    print(f"\nğŸ“ Files created:")
    print(f"   - Backup: {BACKUP_FILE}")
    print(f"   - Normalized: {OUTPUT_FILE}")
    print(f"\nğŸ’¡ To use normalized file, rename it to:")
    print(f"   mv {OUTPUT_FILE} {INPUT_FILE}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Main
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if __name__ == "__main__":
    normalize_json_file()
